{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Day 01\n",
        "---\n",
        "\n",
        "## What is Machine Learning\n",
        "Machine learning is a subset of artificial intelligence (AI) that allows software applications to become more accurate in predicting outcomes without being explicitly programmed to do so.\n",
        "\n",
        "In machine Learning algorithms we give Data and the corresponding output it should have given as an output and it figures out the underlying Mechanish/procudeure behind it.\n",
        "\n",
        "\n",
        "##Where is ML necessary?\n",
        "1. Writing a program for everything may not be possible eg: Spam email classifier. In ML we write one algorithm.\n",
        "2. In places where the number of cases are very high. eg: Dog, Cat classifier. In this case variety of breeds of dogs and cats exist. writing code for dixtinction is difficult and putting too many conditions might be confusing.\n",
        "3. Data Analysis, and Data Mining: Dta pr ML model lagayenge. After applying a ML model on data if some new info can be extracted, then that is data mining.\n",
        "---\n",
        "# Day 02\n",
        "## AI vs ML vs DL\n",
        "1. AI, 2. AI ka subset is ML, 3. ML ka subset is DL\n",
        "##Artificial Intelligence (AI)\n",
        "AI is a broad field that encompasses the development of intelligent agents that can reason, learn, and act autonomously. It aims to create systems that can mimic human intelligence and perform tasks that typically require human cognition.\n",
        "\n",
        "  ## Machine Learning (ML)\n",
        "ML is a subset of AI that focuses on the development of algorithms that allow computers to learn from data without being explicitly programmed. It enables systems to automatically improve their performance on a specific task by learning from experience.\n",
        "\n",
        "  ## Deep Learning (DL)\n",
        "DL is a subfield of ML that utilizes artificial neural networks with multiple layers to learn complex representations of data. It has achieved remarkable success in various domains, such as image recognition, natural language processing, and speech recognition.\n",
        "\n",
        "In ML, after some amount of data, saturation happens, and after some amt of data providing more data, does nothing on the accuracy. but for DL, increasing teh amount of data does incerase the accuracy.\n",
        "\n",
        "---\n",
        "#Day 03\n",
        "#Types of ML\n",
        "1. Supervised:   a.Regression  b. Classification\n",
        "2. Unsupervised: a. Clustering b. Dimenstionality Reduction c. Anamoly Detection d. Association\n",
        "3. Semi-Supervised\n",
        "4. Reinforcement Learning\n",
        "\n",
        "ML is Aall about learning from data.\n",
        "\n",
        "##Supervised Learning:\n",
        "If hamare paas Input and Output explicitly defined hai, basically labelled hai, then for new input, hame output\n",
        "Agar dataset me input and output hai, and hamara kaam input output ke beech relationship shamajhkr, naye input pr prediction karna hai, then that is Supervised Learning.\n",
        "\n",
        "Data can be: 1. Numerical-age wt, cgpa 2. Categorical-gender, nationality\n",
        "  * Regression:If Output column Numerical hai toh, Regression\n",
        "  * Classification: If output column Categorical hai, then Classification\n",
        "\n",
        "## Unsupervised Machine Learning:\n",
        "  We have only Input.\n",
        "  * Clustering\n",
        "  * Dimentionality Reduction\n",
        "  * Anamoly Reduction\n",
        "  * Association Rule Learning\n",
        "\n",
        "### Clustering:\n",
        "  Clustering is a type of unsupervised machine learning technique. It is used to group similar data points together based on their inherent patterns or similarities, without any pre-defined labels or categories.\n",
        "\n",
        "  Think of it like this: you have a basket of fruits without any labels, and you want to group them. You might group them by color, size or shape. Clustering algorithms do something similar with data.\n",
        "\n",
        "### Dimensionality Reduction:\n",
        "  Dimensionality reduction is a technique used to reduce the number of features (or dimensions) in a dataset while preserving as much of the important information as possible.\n",
        "\n",
        "\n",
        "  Is used in visualisation of data, where the dimension of data is very high. and thus direct plotting isnt really possible.\n",
        "\n",
        "  ### Why is this useful?\n",
        "\n",
        "  * Simplifies the data: High-dimensional data can be complex and difficult to visualize or analyze. Reducing the number of dimensions can make the data easier to work with.\n",
        "  * Improves model performance: Sometimes, having too many features can lead to overfitting in machine learning models. Dimensionality reduction can help prevent this by focusing on the most relevant features.\n",
        "\n",
        "### Anamoly Detection:\n",
        "  Anomaly detection, also known as outlier detection, is the process of identifying data points that deviate significantly from the normal or expected behavior within a dataset. These unusual data points are called anomalies or outliers.\n",
        "\n",
        "  ### Why is this useful?\n",
        "  * Fraud detection: Identifying unusual transactions can help prevent fraudulent activities.\n",
        "  * Network security: Detecting unusual network traffic patterns can indicate potential cyber attacks.\n",
        "\n",
        "### Association Learning:\n",
        "  * Association rule learning is a technique used to discover interesting relationships or associations among variables in large datasets. It aims to find rules that describe how often items or events occur together.\n",
        "  * Think of a supermarket. Association rule learning can be used to analyze customer purchase data and identify patterns like:\n",
        "\n",
        "    \"Customers who buy diapers also tend to buy beer.\"\n",
        "    \"People who purchase bread often also buy butter.\"\n",
        "\n",
        "### Semi- Supervised Learning:\n",
        "  Semi-supervised learning is a machine learning approach that combines elements of both supervised and unsupervised learning. It leverages a small amount of labeled data along with a larger amount of unlabeled data to train models.\n",
        "\n",
        "  They have a massive amount of photos uploaded by users, but only a small fraction of those photos have faces manually tagged with names. This is where semi-supervised learning comes in.\n",
        "\n",
        "### Reinforcement Learning:\n",
        "  Reinforcement learning (RL) is a type of machine learning where an agent learns to make decisions by interacting with an environment. The agent receives feedback in the form of rewards or penalties based on its actions, and its goal is to learn a policy that maximizes its cumulative reward over time.\n",
        "\n",
        "    Key Concepts:\n",
        "\n",
        "  * Agent: The entity that interacts with the environment and makes decisions.\n",
        "  * Environment: The world or system that the agent interacts with.\n",
        "  * State: A representation of the current situation in the environment.\n",
        "  * Action: A choice that the agent can make to affect the environment.\n",
        "  * Reward: A numerical signal that the agent receives from the environment, indicating the goodness of its actions.\n",
        "    How it Works:\n",
        "\n",
        "  * Observation: The agent observes the current state of the environment.\n",
        "  * Action Selection: Based on its current policy, the agent chooses an action to take.\n",
        "  * Environment Response: The environment transitions to a new state based on the agent's action.\n",
        "  * Reward: The agent receives a reward signal from the environment, indicating the immediate consequence of its action.\n",
        "  * Policy Update: The agent updates its policy based on the reward and the observed transition, aiming to improve its future decision-making.\n",
        "\n",
        "  ---\n",
        "  # Day 04:\n",
        "\n",
        "---\n",
        "## Batch Machine Learning- Offline Models\n",
        "  No incremental Training, jo data hai wo pura ka pura initially ji use hojata hai. Train the whole lot eksaath.\n",
        "  1. data\n",
        "  2. model\n",
        "  3. test\n",
        "  4. server\n",
        "\n",
        "  A batch ML model, in the context of machine learning, refers to a model that is trained on a fixed dataset all at once, as opposed to being updated incrementally with new data as it becomes available.\n",
        "\n",
        "  Here's how it works:\n",
        "\n",
        "  *  Data Collection: Gather and prepare a complete dataset that will be used for training.\n",
        "  * Model Training: Train the ML model using the entire dataset in one go.\n",
        "  * Deployment: Deploy the trained model to make predictions on new, unseen data.\n",
        "  * Periodic Retraining: As new data becomes available or the environment changes, the model may need to be retrained on an updated dataset. This retraining is typically done offline, in batches.\n",
        "\n",
        "  This makes the model static, but the environment is dynamic and constantly changing, so need for re raining the whole model frequently.\n",
        "\n",
        "  Disadavntages:\n",
        "    1. Availibility\n",
        "    2. Hardware Limitation\n",
        "    3. Lots of data\n",
        "\n",
        "\n",
        "      Pros:\n",
        "\n",
        "  * Simplicity: Batch training is often easier to implement and manage compared to online or incremental learning.\n",
        "  * Efficiency: Training on the entire dataset at once can be computationally efficient.\n",
        "Stability: Batch models are less prone to fluctuations caused by individual data points, leading to more stable predictions.\n",
        "\n",
        "      Cons:\n",
        "  * Lack of Adaptability: Batch models cannot adapt to changes in the data distribution or environment without being retrained.\n",
        "  * Latency: Retraining the model on new data introduces a delay in incorporating fresh information.\n",
        "\n",
        "      When to Use Batch ML:\n",
        "\n",
        "  * Static Environments: When the underlying patterns in the data are relatively stable and don't change frequently.\n",
        "  * Large Datasets: When you have a large amount of historical data available for training.\n",
        "Computational Constraints: When you have limited resources for continuous model updates.\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "## Online Machine Learning\n",
        "Incremental in nature. Training can be done on production.\n",
        "1. use small chunk of data to the model, model learns, we test the model, and then the model is on the server, and then more data is fed to the model, by which it both, 1. learns, and 2. predicts\n",
        "eg chatbots.\n",
        "\n",
        "  * Learning Data Rate:\n",
        "  Learning data rate refers to the speed at which new data is fed to the model for learning. It's a crucial parameter that needs to be carefully tuned.\n",
        "\n",
        "    Here's why:\n",
        "\n",
        "  * Too fast: If the learning rate is too high, the model might overreact to new data points and become unstable, leading to fluctuating performance.\n",
        "  * Too slow: If the learning rate is too low, the model might not adapt quickly enough to changes in the data distribution and miss out on capturing important patterns.\n",
        "\n",
        "  * Out of Core Learning: Data is so huge, you cant use batch, so need to use Batch. Convert big data into smaller chunks,and trained in offline/batch type.\n",
        "\n",
        "  * Disadvantage:\n",
        "  1. Tricky\n",
        "  2. Risky\n",
        "\n",
        "\n",
        "---\n",
        "#Instance Based Learning VS Model Based Learning\n",
        "Learning is of two types:\n",
        "1. Memorization\n",
        "2. Concept Bsed\n",
        "\n",
        "## Instance-Based Learning (Memory-Based Learning)\n",
        "  mwmoirization\n",
        "  * No explicit model: Doesn't construct a general model during training. Instead, it stores all the training data.\n",
        "  * Prediction based on similarity: When a new input is encountered, it finds the most similar instances (data points) from the stored training data and uses them to make predictions.\n",
        "  * Examples: k-Nearest Neighbors (k-NN), Locally Weighted Regression.\n",
        "---\n",
        "\n",
        "## Model-Based Learning\n",
        "\n",
        "  * Constructs a model: During training, it builds a generalized model that captures the relationships within the data.\n",
        "  * Prediction using the model: When a new input is presented, the learned model is used to make predictions, without directly referencing the original training data.\n",
        "  * Examples: Linear Regression, Decision Trees, Neural Networks.\n",
        "\n",
        "\n",
        "  1. Preprocessing dono me karne hai\n",
        "  2. model me parameters hote hai, but instance, wale me until a new data point is not received, no calculations are done.\n",
        "  3. instance wale me koi model hota hi nhi hai, but model wale me model ko save karte hai.\n",
        "  4. instance no generalization before scoring, otherwise already generalized.\n",
        "  5. instance wale me training data is a must, in other can remove input data.\n",
        "  6. instance ko lazy bhi boltw hai.\n",
        "\n",
        "  ---\n",
        "  # Challenges in ML\n",
        "\n",
        "  ---\n",
        "\n",
        "  1. Gathering Data is difficult\n",
        "  2. Insufficient Data\n",
        "  3. Poor Data Quality\n",
        "  4. Non Representative Data\n",
        "  5. Sampling Noise and Sampling Bias\n",
        "  6. Irrelevant Features\n",
        "  7. Overfitting and Underfitting\n",
        "  8. Feature Engineering\n",
        "  9. Computational Complexity\n",
        "\n",
        "  ---\n",
        "\n",
        "# Application Of ML\n",
        "---\n",
        "1. Retail- BigBasket, Amazon: Personalized Recommendations,\n",
        "Customer Churn Prediction: Predicting which customers are likely to stop shopping with a retailer and taking proactive measures to retain them.\n",
        "2.\n",
        "---\n",
        "#Machine Learning Development Life Cycle\n",
        "---\n",
        "Data can be gathered from varying places:\n",
        "  1. csv files\n",
        "  2. APIs se fetch use karke, json file me data\n",
        "  3. Web Scraping, websites like trivago, do data scraping from multiple online hotel websites, same way price analyzer where a products prices are compared across various sides\n",
        "  4. Database: but database isnt directly used kyuki website down hoskti hai, isiliye we make database warehouse\n",
        "  5. present in clusters\n",
        "\n",
        "## Steps:\n",
        "1. Frame teh Problem\n",
        "2. Gathering Data\n",
        "3. Data Processing: data is bound to be unclean, can have problems. Remove duplicates, remove misiing avlues, remiove outliers, scaling.\n",
        "4. Exploratory Data Analysis: Study teh relationship between input and output, graph plotting, visualsing, mean std variation, bivariant analysis, multivariant analysis, outlier database convert to balanced, imbalanced made balanaced, imbalanced means ki data biased na ho.\n",
        "5. Feature engineering and Selection:\n",
        "jab features bohot zyada hojaye toh, aise features jo final model me na ya kam required ho toh, removing them ya using them to extract more important and reliant data.\n",
        "6. Model Training, Evaluation and Selection:\n",
        "Trying out all possible models and algorithms so as to see which one performs the best for your data.\n",
        "  Ensemble Learning:\n",
        "  Combining or fusing of algorithm methodologies of multiple algorithms according to the required output.\n",
        "7. Model Deployment: Model ko binary file banate hai, and conevrt into api, and teh inputs on the website are fetched and given to this binary fiel which then makes the predictions.\n",
        "8. Testing: eg:A/B Testing\n",
        "9. Optimise: data backup, model backup, rollback and then go live, load balancing, retraining the model often, Model can become rotten.\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ZLhvdzxIaUxQ"
      }
    }
  ]
}